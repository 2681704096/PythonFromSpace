{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://github.com/anjesh/Jupyter-GeoJson-Mapping\n",
    "# https://www.ryanbaumann.com/blog/2016/4/3/embedding-mapbox-plots-in\n",
    "#https://github.com/jwass/geojsonio.py-jupyter-notebooks\n",
    "# http://jupyter-gmaps.readthedocs.io/en/latest/gmaps.html\n",
    "#https://github.com/planetlabs/planet-client-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup \n",
    "Let's setup our environment. We'll pull in the the usual gis suspects and setup a leaflet map, read our API keys from a json file, and setup our Planet client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named ipyleaflet",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-107fe70f4c0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mndimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m from ipyleaflet import (\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mMap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mMarker\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named ipyleaflet"
     ]
    }
   ],
   "source": [
    "from planet import api\n",
    "from planet.api import filters\n",
    "from sys import stdout\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import urllib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "import rasterio.tools.mask as rio_mask\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import scipy\n",
    "import datetime \n",
    "from scipy import ndimage\n",
    "\n",
    "from ipyleaflet import (\n",
    "    Map,\n",
    "    Marker,\n",
    "    TileLayer, ImageOverlay,\n",
    "    Polyline, Polygon, Rectangle, Circle, CircleMarker,\n",
    "    GeoJSON,\n",
    "    DrawControl\n",
    ")\n",
    "from traitlets import link\n",
    "\n",
    "from IPython.display import display, Image, HTML\n",
    "%matplotlib inline\n",
    "\n",
    "# will pick up api_key via environment variable PL_API_KEY\n",
    "# but can be specified using `api_key` named argument\n",
    "api_keys = json.load(open(\"apikeys.json\",'r'))\n",
    "client = api.ClientV1(api_key=api_keys[\"PLANET_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a slippy map to get GeoJSON\n",
    "\n",
    "* The planet API allows you to query using a [geojson](https://en.wikipedia.org/wiki/GeoJSON) which is a special flavor of json.\n",
    "* We are going to create a slippy map using leaflet and apply the Planet 2017 Q1 mosaic as the basemap. This requires our api key.\n",
    "* We are going to add a special draw handler that shoves a draw region into a object so we get the geojson.\n",
    "* If you don't want to do this, or need a fixed query try [geojson.io](http://geojson.io/#map=2/20.0/0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'api_keys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1a106a765e62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmosaicsTilesURL_base\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://tiles0.planet.com/experimental/mosaics/planet-tiles/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmosaicsSeries\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/gmap/{z}/{x}/{y}.png'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Planet tile server url\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmosaicsTilesURL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmosaicsTilesURL_base\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'?api_key='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mapi_keys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"PLANET_API_KEY\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;31m# Map Settings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Define colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'api_keys' is not defined"
     ]
    }
   ],
   "source": [
    "# Basemap Mosaic (v1 API)\n",
    "mosaicsSeries = 'global_quarterly_2017q1_mosaic'\n",
    "# Planet tile server base URL (Planet Explorer Mosaics Tiles)\n",
    "mosaicsTilesURL_base = 'https://tiles0.planet.com/experimental/mosaics/planet-tiles/' + mosaicsSeries + '/gmap/{z}/{x}/{y}.png'\n",
    "# Planet tile server url\n",
    "mosaicsTilesURL = mosaicsTilesURL_base + '?api_key=' + api_keys[\"PLANET_API_KEY\"]\n",
    "# Map Settings \n",
    "# Define colors\n",
    "colors = {'blue': \"#009da5\"}\n",
    "# Define initial map center lat/long\n",
    "center = [45.5231, -122.6765]\n",
    "# Define initial map zoom level\n",
    "zoom = 11\n",
    "# Set Map Tiles URL\n",
    "planetMapTiles = TileLayer(url= mosaicsTilesURL)\n",
    "# Create the map\n",
    "m = Map(\n",
    "    center=center, \n",
    "    zoom=zoom,\n",
    "    default_tiles = planetMapTiles # Uncomment to use Planet.com basemap\n",
    ")\n",
    "# Define the draw tool type options\n",
    "polygon = {'shapeOptions': {'color': colors['blue']}}\n",
    "rectangle = {'shapeOptions': {'color': colors['blue']}} \n",
    "\n",
    "# Create the draw controls\n",
    "# @see https://github.com/ellisonbg/ipyleaflet/blob/master/ipyleaflet/leaflet.py#L293\n",
    "dc = DrawControl(\n",
    "    polygon = polygon,\n",
    "    rectangle = rectangle\n",
    ")\n",
    "# Initialize an action counter variable\n",
    "actionCount = 0\n",
    "AOIs = {}\n",
    "\n",
    "# Register the draw controls handler\n",
    "def handle_draw(self, action, geo_json):\n",
    "    # Increment the action counter\n",
    "    global actionCount\n",
    "    actionCount += 1\n",
    "    # Remove the `style` property from the GeoJSON\n",
    "    geo_json['properties'] = {}\n",
    "    # Convert geo_json output to a string and prettify (indent & replace ' with \")\n",
    "    geojsonStr = json.dumps(geo_json, indent=2).replace(\"'\", '\"')\n",
    "    AOIs[actionCount] = json.loads(geojsonStr)\n",
    "    \n",
    "# Attach the draw handler to the draw controls `on_draw` event\n",
    "dc.on_draw(handle_draw)\n",
    "m.add_control(dc)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the Planet API.\n",
    "* First we'll grab our geojson area of interest (AOI) and use it to construct a query.\n",
    "* We'll then build a search to search that area looking for PSScene3Band\n",
    "* We have lots of products: RapidEye, PlanetScope (PS) 3 and 4 band, LandSat, and Sentinel are all possible.\n",
    "* Once we have our query, we'll do the search. We will then iterate over the results, slurp up the data, and put them in a pandas data frame for easy sorting.\n",
    "* We'll print the first few so we're sure it works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print AOIs[1]\n",
    "myAOI = AOIs[1][\"geometry\"]\n",
    "\n",
    "# build a query using the AOI and\n",
    "# a cloud_cover filter that excludes 'cloud free' scenes\n",
    "query = filters.and_filter(\n",
    "    filters.geom_filter(myAOI),\n",
    "    filters.range_filter('cloud_cover', gt=0),\n",
    ")\n",
    "\n",
    "# build a request for only PlanetScope imagery\n",
    "request = filters.build_search_request(\n",
    "    query, item_types=['PSScene3Band']\n",
    ")\n",
    "\n",
    "# if you don't have an API key configured, this will raise an exception\n",
    "result = client.quick_search(request)\n",
    "scenes = []\n",
    "planet_map = {}\n",
    "for item in result.items_iter(limit=None):\n",
    "    planet_map[item['id']]=item\n",
    "    props = item['properties']\n",
    "    props[\"id\"] = item['id']\n",
    "    props[\"geometry\"] = item[\"geometry\"]\n",
    "    props[\"thumbnail\"] = item[\"_links\"][\"thumbnail\"]\n",
    "    scenes.append(props)\n",
    "scenes = pd.DataFrame(data=scenes)\n",
    "scenes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup\n",
    "The returned acquisition, publish, and update times are strings, we'll convert them to datatime objects so we wan search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now let's clean up the datetime stuff\n",
    "scenes[\"acquired\"] = pd.to_datetime(scenes[\"acquired\"])\n",
    "scenes[\"published\"] = pd.to_datetime(scenes[\"published\"])\n",
    "scenes[\"updated\"] = pd.to_datetime(scenes[\"updated\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering our search using pandas.\n",
    "* Using our dataframe we will filter the scenes to just what we want.\n",
    "* First we want scenes with less than 10% clouds.\n",
    "* Second we want standard quality images. Test images may not be high quality.\n",
    "* Third well only look for scenes since February.\n",
    "* Finally we will create a new data frame with our queries and print the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's get it down to just good, recent, clear scenes\n",
    "clear = scenes['cloud_cover']<0.1\n",
    "good = scenes['quality_category']==\"standard\"\n",
    "recent = scenes[\"acquired\"] > datetime.date(year=2017,month=2,day=1)\n",
    "good_scenes = scenes[(good&clear&recent)]\n",
    "good_scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see what we got. \n",
    "* The API returns a handy thumbnail link.\n",
    "* Let's tell jupyter to show it.\n",
    "* You may need to login to planet explorer to have auth. \n",
    "    * If this is the case just print the urls and paste them into your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for img in good_scenes[\"thumbnail\"].tolist():\n",
    "    imgs.append(Image(url=img))\n",
    "display(*imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Activation and Downloading\n",
    "* Full resolution uncompressed satellite images are *big* and there are lots of ways to view them.\n",
    "* For this reason Planet generally keeps images in their native format and only processes them on customer requests. There is some caching of processed scenes, but this is the exception not the rule.\n",
    "* All images must be activated prior to downloading and this can take some time based on demand.\n",
    "* Additionally we need to determine what sort of product we want to download. Generally speaking there are three kinds of scenes:\n",
    "    * Analytic - multi-band full resolution images that have not been processed. These are like raw files for DSLR camers.\n",
    "    * Visual - these are color corrected rectified tifs. If you are just starting out this is your best call.\n",
    "    * UDM - Usable data mask. This mask can be used to find bad pixels and columns and to mask out areas with clouds.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_products(client, scene_id, asset_type='PSScene3Band'):    \n",
    "    \"\"\"\n",
    "    Ask the client to return the available products for a \n",
    "    given scene and asset type. Returns a list of product \n",
    "    strings\n",
    "    \"\"\"\n",
    "    out = client.get_assets_by_id(asset_type,scene_id)\n",
    "    temp = out.get()\n",
    "    return temp.keys()\n",
    "\n",
    "def activate_product(client, scene_id, asset_type=\"PSScene3Band\",product=\"analytic\"):\n",
    "    \"\"\"\n",
    "    Activate a product given a scene, an asset type, and a product.\n",
    "    \n",
    "    On success return the return value of the API call and an activation object\n",
    "    \"\"\"\n",
    "    temp = client.get_assets_by_id(asset_type,scene_id)  \n",
    "    products = temp.get()\n",
    "    if( product in products.keys() ):\n",
    "        return client.activate(products[product]),products[product]\n",
    "    else:\n",
    "        return None \n",
    "\n",
    "def download_and_save(client,product):\n",
    "    \"\"\"\n",
    "    Given a client and a product activation object download the asset. \n",
    "    This will save the tiff file in the local directory and return its \n",
    "    file name. \n",
    "    \"\"\"\n",
    "    out = client.download(product)\n",
    "    fp = out.get_body()\n",
    "    fp.write()\n",
    "    return fp.name\n",
    "\n",
    "def scenes_are_active(scene_list):\n",
    "    \"\"\"\n",
    "    Check if all of the resources in a given list of\n",
    "    scene activation objects is read for downloading.\n",
    "    \"\"\"\n",
    "    retVal = True\n",
    "    for scene in scene_list:\n",
    "        if scene[\"status\"] != \"active\":\n",
    "            print \"{} is not ready.\".format(scene)\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scenes ACTIVATE!\n",
    "* Given our good scenes list we will convert the data frame \"id\" column into a list and activate every item in that list. \n",
    "* For this example we are going to default to using a 3Band visual product but I have included some four band methods to help you out.\n",
    "* Activation usually takes about 5-15 minutes so get some coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_get = good_scenes[\"id\"].tolist()\n",
    "activated = []\n",
    "waiter = []\n",
    "for scene in to_get:\n",
    "    product_types = get_products(client,scene)\n",
    "    for p in product_types:\n",
    "        if p == \"visual\": # p == \"basic_analytic_dn\"\n",
    "            print \"Activating {0} for scene {1}\".format(p,scene)\n",
    "            _,product = activate_product(client,scene,product=p)\n",
    "            activated.append(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Scenes\n",
    "* In this section we will see if our scenes have been activated.\n",
    "* If they are activated the client object will have its status flag set to active.\n",
    "* Once that is done we will then save the scenes to the local directory.\n",
    "* A smart engineer would set a path variable to store these files and check if the asset has already been downloaded prior to downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tiff_files = []\n",
    "#if scenes_are_active(activated):\n",
    "for to_download in activated:\n",
    "    if to_download[\"status\"] == \"active\":\n",
    "        fname = download_and_save(client,to_download)\n",
    "        tiff_files.append(fname)\n",
    "    else:\n",
    "        print \"Could not download, still activating\"\n",
    "#else:\n",
    "#    print \"Scenes aren't ready yet\"\n",
    "\n",
    "print tiff_files \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Images\n",
    "* There are a varitety of ways to load tif data including Rasterio, GDAL, OpenCV, SKImage. \n",
    "* Today we are going to use rasterio and load each channel into a numpy array.\n",
    "* Since the visual 3Band products are rotated we can also open a mask layer for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_image4(filename):\n",
    "    \"\"\"Return a 4D (r, g, b, nir) numpy array with the data in the specified TIFF filename.\"\"\"\n",
    "    path = os.path.abspath(os.path.join('./', filename))\n",
    "    if os.path.exists(path):\n",
    "        with rasterio.open(path) as src:\n",
    "            b, g, r, nir = src.read()\n",
    "            return np.dstack([r, g, b, nir])\n",
    "        \n",
    "def load_image3(filename):\n",
    "    \"\"\"Return a 3D (r, g, b) numpy array with the data in the specified TIFF filename.\"\"\"\n",
    "    path = os.path.abspath(os.path.join('./', filename))\n",
    "    if os.path.exists(path):\n",
    "        with rasterio.open(path) as src:\n",
    "            b,g,r,mask = src.read()\n",
    "            return np.dstack([b, g, r])\n",
    "        \n",
    "def get_mask(filename):\n",
    "    \"\"\"Return a 1D mask numpy array with the data in the specified TIFF filename.\"\"\"\n",
    "    path = os.path.abspath(os.path.join('./', filename))\n",
    "    if os.path.exists(path):\n",
    "        with rasterio.open(path) as src:\n",
    "            b,g,r,mask = src.read()\n",
    "            return np.dstack([mask])\n",
    "\n",
    "def rgbir_to_rgb(img_4band):\n",
    "    \"\"\"Convert an RGBIR image to RGB\"\"\"\n",
    "    return img_4band[:,:,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Images and Use Matplotlib to show them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tiff_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-5f98962fc4e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtiff_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimg_files\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mload_image3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tiff_files' is not defined"
     ]
    }
   ],
   "source": [
    "img_files = []\n",
    "masks = []\n",
    "for fname in tiff_files:\n",
    "    img_files.append(load_image3(fname))\n",
    "    masks.append(get_mask(fname))\n",
    "i = 0\n",
    "for img,name in zip(img_files,tiff_files):\n",
    "    plt.figure(i,figsize=(6,12))\n",
    "    plt.imshow(img)\n",
    "    plt.title(name)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Histogram\n",
    "* Next up we'll plot the histogram of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy.ma as ma\n",
    "def plot_hist4(img_4band,title=\"\"):\n",
    "    r, g, b, nir = img_4band[:, :, 0], img_4band[:, :, 1], img_4band[:, :, 2], img_4band[:, :, 3]\n",
    "    for slice_, name, color in ((r,'r', 'red'),(g,'g', 'green'),(b,'b', 'blue'), (nir, 'nir', 'magenta')):\n",
    "        plt.hist(slice_.ravel(), bins=100, \n",
    "                 range=[0,img_4band.max()], \n",
    "                 label=name, color=color, histtype='step')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    \n",
    "def plot_hist3(img_3band,mask,title=\"\"):\n",
    "    r, g, b = img_3band[:, :, 0], img_3band[:, :, 1], img_3band[:, :, 2]\n",
    "    r = ma.masked_array(r,mask=mask)\n",
    "    g = ma.masked_array(g,mask=mask)\n",
    "    b = ma.masked_array(b,mask=mask)\n",
    "    for slice_, name, color in ((r,'r', 'red'),(g,'g', 'green'),(b,'b', 'blue')):\n",
    "        plt.hist(slice_.ravel(), bins=25, \n",
    "                 range=[0,img_3band.max()], \n",
    "                 label=name, color=color, histtype='step')\n",
    "    plt.title(title)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for img,name,mask in zip(img_files,tiff_files,masks):\n",
    "    plt.figure(i)\n",
    "    plot_hist3(img,mask=mask,title=name)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decomposing Channels\n",
    "* We can also decompose the channels of the image. \n",
    "* Sometimes it is useful to work just in a single channel.\n",
    "* Other times channels can be used to do useful things, like filter out clouds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_bands4(img,title=\"\",i=0):\n",
    "    fig = plt.figure(i)\n",
    "    fig.set_size_inches(24, 3)\n",
    "    r, g, b, nir = img[:, :, 0], img[:, :, 1], img[:, :, 2], img[:, :, 3]\n",
    "    fig.suptitle(title)\n",
    "    for i, (x, c) in enumerate(((r, 'r'), (g, 'g'), (b, 'b'), (nir, 'near-ir'))):\n",
    "        a = fig.add_subplot(1, 4, i+1)\n",
    "        a.set_title(c)\n",
    "        plt.imshow(x)\n",
    "        \n",
    "def plot_bands3(img,title=\"\",i=0):\n",
    "    fig = plt.figure(i)\n",
    "    fig.set_size_inches(24, 5)\n",
    "    r, g, b = img[:, :, 0], img[:, :, 1], img[:, :, 2]\n",
    "    fig.suptitle(title)\n",
    "    for i, (x, c) in enumerate(((r, 'r'), (g, 'g'), (b, 'b'))):\n",
    "        a = fig.add_subplot(1, 4, i+1)\n",
    "        a.set_title(c)\n",
    "        plt.imshow(x)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "for img,name in zip(img_files,tiff_files):\n",
    "    plot_bands3(img,title=name,i=i)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myAOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fiona\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "import matplotlib as mpl\n",
    "from descartes import PolygonPatch\n",
    "\n",
    "src = rasterio.open(\"20170415_201830_1_0d06_3B_Visual.tif\")\n",
    "\n",
    "with fiona.open(\"./test.json\", \"r\") as shapefile:\n",
    "    features = [feature[\"geometry\"] for feature in shapefile]\n",
    "\n",
    "rasterio.plot.show(src)\n",
    "rasterio.plot.show_hist(src)\n",
    "ax = mpl.pyplot.gca()\n",
    "\n",
    "patches = [PolygonPatch(feature,edgecolor=\"red\", facecolor=\"none\", linewidth=2) for feature in features]\n",
    "#ax.add_collection(mpl.collections.PatchCollection(patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rasterio.mask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://mapbox.s3.amazonaws.com/playground/perrygeo/rasterio-docs/cookbook.html\n",
    "#/usr/local/lib/python2.7/dist-packages/rasterio/mask.py:72: UserWarning: GeoJSON outside bounds of existing output raster. Are they in different coordinate reference systems?\n",
    "#  \"reference systems?\")\n",
    "import fiona\n",
    "# https://gist.github.com/sgillies/8655640\n",
    "#https://geohackweek.github.io/vector/04-geopandas-intro/\n",
    "# https://github.com/dwtkns/gdal-cheat-sheet\n",
    "# http://gis-pdx.opendata.arcgis.com/datasets/neighborhood-boundaries\n",
    "import rasterio\n",
    "\n",
    "\n",
    "with fiona.open(\"./Neighborhood_Boundaries.shp\", \"r\") as shapefile:\n",
    "#with fiona.open(\"./POLYGON.shp\", \"r\") as shapefile:\n",
    "    geoms = [feature[\"geometry\"] for feature in shapefile]\n",
    "    print geoms\n",
    "    \n",
    "print tiff_files[0]\n",
    "with rasterio.open(\"20170415_201830_1_0d06_3B_Visual.tif\",crs='EPSG:3857') as src:\n",
    "    # CRS({'init': u'epsg:32610'\n",
    "    out_image, out_transform = rio_mask.mask(src, geoms)#crop=True)\n",
    "    out_meta = src.meta.copy()\n",
    "\n",
    "out_meta.update({\"driver\": \"GTiff\",\n",
    "                 \"height\": out_image.shape[1],\n",
    "                 \"width\": out_image.shape[2],\n",
    "                 \"transform\": out_transform})\n",
    "\n",
    "tmp_file = \"/tmp/masked.tif\"\n",
    "with rasterio.open(tmp_file, \"w\", **out_meta) as dest:\n",
    "    dest.write(out_image)\n",
    "    \n",
    "img = load_image3(tmp_file)\n",
    "plt.figure(0,figsize=(6,12))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "ref_colors = [[],[],[]]\n",
    "for _file in jpg_list:\n",
    "    # keep only the first 3 bands, RGB\n",
    "    _img = mpimg.imread(os.path.join(PLANET_KAGGLE_JPEG_DIR, _file))[:,:,:3]\n",
    "    # Flatten 2-D to 1-D\n",
    "    _data = _img.reshape((-1,3))\n",
    "    # Dump pixel values to aggregation buckets\n",
    "    for i in range(3): \n",
    "        ref_colors[i] = ref_colors[i] + _data[:,i].tolist()\n",
    "    \n",
    "ref_colors = np.array(ref_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://pcjericks.github.io/py-gdalogr-cookbook/raster_layers.html\n",
    "# http://geospatialpython.com/2011/02/clip-raster-using-shapefile.html\n",
    "from osgeo import gdal, ogr\n",
    "import sys\n",
    "# this allows GDAL to throw Python Exceptions\n",
    "gdal.UseExceptions()\n",
    "\n",
    "#\n",
    "#  get raster datasource\n",
    "#\n",
    "src_ds = gdal.Open( \"20170415_201830_1_0d06_3B_Visual.tif\" )\n",
    "if src_ds is None:\n",
    "    print 'Unable to open %s' % src_filename\n",
    "    sys.exit(1)\n",
    "\n",
    "try:\n",
    "    srcband = src_ds.GetRasterBand(3)\n",
    "except RuntimeError, e:\n",
    "    # for example, try GetRasterBand(10)\n",
    "    print 'Band ( %i ) not found' % band_num\n",
    "    print e\n",
    "    sys.exit(1)\n",
    "\n",
    "#\n",
    "#  create output datasource\n",
    "#\n",
    "dst_layername = \"POLYGONIZED_STUFF\"\n",
    "drv = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "dst_ds = drv.CreateDataSource( \"./POLYGON.shp\" )\n",
    "dst_layer = dst_ds.CreateLayer(dst_layername, srs = None )\n",
    "\n",
    "gdal.Polygonize( srcband, None, dst_layer, -1, [], callback=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(dst_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RasterClipper.py - clip a geospatial image using a shapefile\n",
    "\n",
    "import operator\n",
    "from osgeo import gdal, gdalnumeric, ogr, osr\n",
    "import Image, ImageDraw\n",
    "\n",
    "# Raster image to clip\n",
    "raster = \"./20170415_201830_1_0d06_3B_Visual.tif\"\n",
    "\n",
    "# Polygon shapefile used to clip\n",
    "shp = \"./POLYGON\"\n",
    "\n",
    "# Name of clip raster file(s)\n",
    "output = \"clip\"\n",
    "\n",
    "# This function will convert the rasterized clipper shapefile \n",
    "# to a mask for use within GDAL.    \n",
    "def imageToArray(i):\n",
    "    \"\"\"\n",
    "    Converts a Python Imaging Library array to a \n",
    "    gdalnumeric image.\n",
    "    \"\"\"\n",
    "    a=gdalnumeric.fromstring(i.tostring(),'b')\n",
    "    a.shape=i.im.size[1], i.im.size[0]\n",
    "    return a\n",
    "\n",
    "def arrayToImage(a):\n",
    "    \"\"\"\n",
    "    Converts a gdalnumeric array to a \n",
    "    Python Imaging Library Image.\n",
    "    \"\"\"\n",
    "    i=Image.fromstring('L',(a.shape[1],a.shape[0]),\n",
    "            (a.astype('b')).tostring())\n",
    "    return i\n",
    "     \n",
    "def world2Pixel(geoMatrix, x, y):\n",
    "  \"\"\"\n",
    "  Uses a gdal geomatrix (gdal.GetGeoTransform()) to calculate\n",
    "  the pixel location of a geospatial coordinate \n",
    "  \"\"\"\n",
    "  ulX = geoMatrix[0]\n",
    "  ulY = geoMatrix[3]\n",
    "  xDist = geoMatrix[1]\n",
    "  yDist = geoMatrix[5]\n",
    "  rtnX = geoMatrix[2]\n",
    "  rtnY = geoMatrix[4]\n",
    "  pixel = int((x - ulX) / xDist)\n",
    "  line = int((ulY - y) / yDist)\n",
    "  return (pixel, line) \n",
    "\n",
    "def histogram(a, bins=range(0,256)):\n",
    "  \"\"\"\n",
    "  Histogram function for multi-dimensional array.\n",
    "  a = array\n",
    "  bins = range of numbers to match \n",
    "  \"\"\"\n",
    "  fa = a.flat\n",
    "  n = gdalnumeric.searchsorted(gdalnumeric.sort(fa), bins)\n",
    "  n = gdalnumeric.concatenate([n, [len(fa)]])\n",
    "  hist = n[1:]-n[:-1] \n",
    "  return hist\n",
    "\n",
    "def stretch(a):\n",
    "  \"\"\"\n",
    "  Performs a histogram stretch on a gdalnumeric array image.\n",
    "  \"\"\"\n",
    "  hist = histogram(a)\n",
    "  im = arrayToImage(a)   \n",
    "  lut = []\n",
    "  for b in range(0, len(hist), 256):\n",
    "    # step size\n",
    "    step = reduce(operator.add, hist[b:b+256]) / 255\n",
    "    # create equalization lookup table\n",
    "    n = 0\n",
    "    for i in range(256):\n",
    "      lut.append(n / step)\n",
    "      n = n + hist[i+b]\n",
    "  im = im.point(lut)\n",
    "  return imageToArray(im)\n",
    "\n",
    "# Load the source data as a gdalnumeric array\n",
    "srcArray = gdalnumeric.LoadFile(raster)\n",
    "\n",
    "# Also load as a gdal image to get geotransform \n",
    "# (world file) info\n",
    "srcImage = gdal.Open(raster)\n",
    "geoTrans = srcImage.GetGeoTransform()\n",
    "\n",
    "# Create an OGR layer from a boundary shapefile\n",
    "shapef = ogr.Open(\"%s.shp\" % shp)\n",
    "lyr = shapef.GetLayer(shp)\n",
    "poly = lyr.GetNextFeature()\n",
    "\n",
    "# Convert the layer extent to image pixel coordinates\n",
    "minX, maxX, minY, maxY = lyr.GetExtent()\n",
    "ulX, ulY = world2Pixel(geoTrans, minX, maxY)\n",
    "lrX, lrY = world2Pixel(geoTrans, maxX, minY)\n",
    "\n",
    "# Calculate the pixel size of the new image\n",
    "pxWidth = int(lrX - ulX)\n",
    "pxHeight = int(lrY - ulY)\n",
    "\n",
    "clip = srcArray[:, ulY:lrY, ulX:lrX]\n",
    "\n",
    "# Create a new geomatrix for the image\n",
    "geoTrans = list(geoTrans)\n",
    "geoTrans[0] = minX\n",
    "geoTrans[3] = maxY\n",
    "\n",
    "# Map points to pixels for drawing the \n",
    "# boundary on a blank 8-bit, \n",
    "# black and white, mask image.\n",
    "points = []\n",
    "pixels = []\n",
    "geom = poly.GetGeometryRef()\n",
    "pts = geom.GetGeometryRef(0)\n",
    "for p in range(pts.GetPointCount()):\n",
    "  points.append((pts.GetX(p), pts.GetY(p)))\n",
    "for p in points:\n",
    "  pixels.append(world2Pixel(geoTrans, p[0], p[1]))\n",
    "rasterPoly = Image.new(\"L\", (pxWidth, pxHeight), 1)\n",
    "rasterize = ImageDraw.Draw(rasterPoly)\n",
    "rasterize.polygon(pixels, 0)\n",
    "mask = imageToArray(rasterPoly)   \n",
    "\n",
    "# Clip the image using the mask\n",
    "clip = gdalnumeric.choose(mask, \\\n",
    "    (clip, 0)).astype(gdalnumeric.uint8)\n",
    "\n",
    "# This image has 3 bands so we stretch each one to make them\n",
    "# visually brighter\n",
    "for i in range(3):\n",
    "  clip[i,:,:] = stretch(clip[i,:,:])\n",
    "\n",
    "# Save ndvi as tiff\n",
    "gdalnumeric.SaveArray(clip, \"%s.tif\" % output, \\\n",
    "    format=\"GTiff\", prototype=raster)\n",
    "\n",
    "# Save ndvi as an 8-bit jpeg for an easy, quick preview\n",
    "clip = clip.astype(gdalnumeric.uint8)\n",
    "gdalnumeric.SaveArray(clip, \"%s.jpg\" % output, format=\"JPEG\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
